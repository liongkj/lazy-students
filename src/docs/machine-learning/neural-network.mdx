---
title: 'Neural Network Links'
description: 'Good reading for NN'
--- 
# RNN
Basic Intuition for Recurrent Neural Networks
Normally used in speech recognition related problems.
Great videos are made by [Michael Phi](https://www.michaelphi.com/)

## Vanilla setup
https://www.youtube.com/watch?v=LHXXI4-IEns
- suffer from short term memory
- could not save context

## LSTM (Long short Term Memory)
https://youtu.be/8HyCNIVRbSU

Or if you prefer reading, this is the [medium post](https://towardsdatascience.com/illustrated-guide-to-lstms-and-gru-s-a-step-by-step-explanation-44e9eb85bf21)

### Advanced Reading:
1. [Understanding LSTM Networks](https://colah.github.io/posts/2015-08-Understanding-LSTMs/)

<br/>

## GRU (Gated Recurrent Units)
- less tensor operation (relative faster)

https://youtu.be/8HyCNIVRbSU?t=580
